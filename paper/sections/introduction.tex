Modern software applications face increasing complexity in runtime error handling and debugging, particularly in distributed environments. Traditional approaches to error management often rely on static analysis tools, logging systems, and manual debugging processes, which can be time-consuming and may not provide immediate, actionable insights. The emergence of Large Language Models (LLMs) has opened new possibilities for intelligent runtime assistance, but their application in production environments has been limited by privacy concerns, connectivity requirements, and the need for real-time processing.

This paper introduces CodeSage, a novel runtime middleware layer that addresses these challenges by combining local LLM inference through the LM Studio API with a standardized Model Context Protocol (MCP) for distributed systems. CodeSage represents a significant advancement in runtime intelligence by shifting AI-assisted debugging from compile-time to runtime, providing immediate, context-aware support for error resolution while maintaining privacy and enabling edge computing scenarios.

The key contributions of this work include:

\begin{itemize}
    \item A runtime middleware architecture that seamlessly integrates with .NET 9 applications to provide real-time error analysis and self-healing capabilities
    \item A privacy-preserving approach to LLM-assisted debugging using local model inference through the LM Studio API
    \item The Model Context Protocol (MCP) for standardized context sharing and metadata management across distributed components
    \item A comprehensive evaluation of the system's effectiveness in handling common runtime errors and providing actionable remediation strategies
\end{itemize}

CodeSage's architecture is designed to intercept unhandled exceptions during application execution, generate rich contextual information, and leverage local LLM inference to provide natural language explanations and remediation suggestions. The system operates fully offline, addressing critical privacy and connectivity constraints while maintaining interoperability through the MCP framework.

The source code for CodeSage, including the implementation of the middleware layer, LM Studio integration, and Model Context Protocol, is available as open-source software at \url{https://github.com/myonathanlinkedin/paper_research}. This repository contains the complete implementation, including the core service interfaces, client implementations, and example applications demonstrating the system's capabilities.

The remainder of this paper is organized as follows: Section II reviews related work in AI-assisted programming, static analysis, and runtime error handling. Section III presents the detailed system architecture of CodeSage, emphasizing the integration of MCP and LM Studio API. Section IV describes the implementation details, including the middleware components and LLM integration. Section V presents case studies demonstrating CodeSage's effectiveness in handling common runtime errors. Section VI evaluates the system's performance and accuracy. Section VII discusses limitations and future work, and Section VIII concludes the paper. 